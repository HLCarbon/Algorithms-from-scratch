{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook will create the Decision Tree algorithm from scratch. The dataset used for this will be the sklearn diabetes which is a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(ds.data)\n",
    "y = np.array(ds.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, we need to make the decision tree. So let's look at the first step. \n",
    "\n",
    "The first step is to decide how we are going to separate the data. How do we find this? Since we don't know the best spli criteria, we will have to find it. We do this by iterating through each column and for each column we test every possible value to split and see which one is the best. However, if a column A can have all possible positive values, there would be infinite values for which to try to split the data. So, to circunvent this, for each column, we try to separate the labels  using only the values of that column that we found in our training data. But now, how do we determine what is the best split. There are different metrics that we can use, however, in this case, we will calculate the variance of the labels on each child node and sum them. The best split is the one that have the lower variance. \n",
    "\n",
    "So, let's build 5 functions:\n",
    " 1) Calculates the variance of a list of values, returning a float \n",
    " 2) For a given n of labels y it sums the values of the variances, returning a float\n",
    " 3) For a given column c and a list it loops through all its values and calculates the variance of the split caused by the value, returning a tuple with (value, sum of variance)\n",
    " 4) For a given value v, return the indexes that are less than that value and the indexes that are equal or greater than that value, as a list of lists.\n",
    " 5) For a matrix X and labels y, it loops through all the columns and executes function 3), calculating the best column and value to split on, returning a dictionary with the index of the column, the value and the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variance(number_list:np.ndarray[float])->float:\n",
    "    n = len(number_list)\n",
    "    if n == 0:\n",
    "        return float('inf')\n",
    "    sum_list = 0\n",
    "    for number in number_list:\n",
    "        sum_list += number\n",
    "    average = sum_list/n\n",
    "    sum = 0\n",
    "    for number in number_list:\n",
    "        sum+=(number-average)**2\n",
    "    variance = sum/n\n",
    "    return variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lists_variances(list_of_lists:list[list[float]])->float:\n",
    "    variance_sum = 0\n",
    "    for number_list in list_of_lists:\n",
    "        variance_sum+=calculate_variance(number_list)\n",
    "    return variance_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_split_indexes(split_value:float, list_column_values:list[float])->list[list[int], list[int]]:\n",
    "    indexes_smaller = []\n",
    "    indexes_eq_bigger = []\n",
    "    for index, value in enumerate(list_column_values):\n",
    "        if value<split_value:\n",
    "            indexes_smaller.append(index)\n",
    "        else:\n",
    "            indexes_eq_bigger.append(index)\n",
    "    return [indexes_smaller, indexes_eq_bigger]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_best_column_variance(float_list:np.ndarray[float], labels:np.ndarray[float])->tuple[float, float]:\n",
    "    min_variance = float('inf')\n",
    "    best_split = float('inf')\n",
    "    for value in float_list:\n",
    "        list_of_lists_of_indexes= calculate_split_indexes(value, float_list)\n",
    "        list_of_lists = []\n",
    "        for index_list in list_of_lists_of_indexes:\n",
    "            list_of_lists.append(labels[index_list])\n",
    "        value_variance = calculate_lists_variances(list_of_lists)\n",
    "        if value_variance< min_variance:\n",
    "            min_variance = value_variance\n",
    "            best_split = value\n",
    "    return (best_split, min_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matrix_best_split(matrix: np.ndarray[float], labels: np.ndarray[float])->dict[str, float]:\n",
    "    result_dictionary = {\n",
    "        \"column_index\":-1,\n",
    "        \"split\":-1,\n",
    "        \"variance\":float('inf')\n",
    "    }\n",
    "    for column_index in range(matrix.shape[1]):\n",
    "        column_values = matrix[:, column_index] #select all values from the column of index column_index\n",
    "        split_value, variance = calculate_best_column_variance(column_values, labels)\n",
    "        if variance<result_dictionary['variance']:\n",
    "            result_dictionary['column_index'] = column_index\n",
    "            result_dictionary['split'] = split_value\n",
    "            result_dictionary['variance'] = variance\n",
    "    return result_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try to determine the best split for our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'column_index': 6,\n",
       " 'split': -0.09862541271332903,\n",
       " 'variance': 5862.262308400307}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_matrix_best_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
